{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import substring, col\n",
    "from pyspark.sql.types import StringType, FloatType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"ESTBAN\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"sep\", \";\")\n",
    "    .csv(\"estban_csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"ano\", substring(col(\"#DATA_BASE\"), 1, 4))\n",
    "df = df.withColumn(\"mes\", substring(col(\"#DATA_BASE\"), 5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(col(\"#DATA_BASE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"columns.json\", \"r\") as f:\n",
    "    columns = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, column in enumerate(df.columns):\n",
    "    df = df.withColumnRenamed(column, columns[index][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('uf', StringType(), True), StructField('cod_mun', StringType(), True), StructField('municipio', StringType(), True), StructField('cnpj', StringType(), True), StructField('nome_instituicao', StringType(), True), StructField('cnpj_agencia', StringType(), True), StructField('110', StringType(), True), StructField('111', StringType(), True), StructField('112', StringType(), True), StructField('113', StringType(), True), StructField('114', StringType(), True), StructField('120', StringType(), True), StructField('130', StringType(), True), StructField('140', StringType(), True), StructField('141_142', StringType(), True), StructField('143', StringType(), True), StructField('144_145_146_147_152', StringType(), True), StructField('153', StringType(), True), StructField('158', StringType(), True), StructField('160', StringType(), True), StructField('161', StringType(), True), StructField('162', StringType(), True), StructField('163', StringType(), True), StructField('164', StringType(), True), StructField('165', StringType(), True), StructField('166', StringType(), True), StructField('167_168', StringType(), True), StructField('169', StringType(), True), StructField('171', StringType(), True), StructField('172', StringType(), True), StructField('173', StringType(), True), StructField('174', StringType(), True), StructField('176', StringType(), True), StructField('180', StringType(), True), StructField('184', StringType(), True), StructField('190', StringType(), True), StructField('200', StringType(), True), StructField('300', StringType(), True), StructField('399', StringType(), True), StructField('401_402_404_411_412_413_414_415_416_417_418_419', StringType(), True), StructField('420', StringType(), True), StructField('430', StringType(), True), StructField('431', StringType(), True), StructField('432', StringType(), True), StructField('433', StringType(), True), StructField('440', StringType(), True), StructField('441_442', StringType(), True), StructField('443', StringType(), True), StructField('444_445_446_447_456_458', StringType(), True), StructField('457', StringType(), True), StructField('460', StringType(), True), StructField('461_462_463_467_468', StringType(), True), StructField('470', LongType(), True), StructField('480', LongType(), True), StructField('481_482_483_484_485_487', LongType(), True), StructField('486', LongType(), True), StructField('490_500', LongType(), True), StructField('610', LongType(), True), StructField('710', LongType(), True), StructField('711', LongType(), True), StructField('712', LongType(), True), StructField('800', LongType(), True), StructField('899', LongType(), True), StructField('cod_mun_ibge', IntegerType(), True), StructField('ano', StringType(), True), StructField('mes', StringType(), True)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cast_json(df, columns):\n",
    "\n",
    "        root_spark_schema = {\"fields\": [], \"type\": \"struct\"}\n",
    "\n",
    "        bq_schema = columns\n",
    "\n",
    "        parse = {\n",
    "            \"BIGNUMERIC\": \"decimal(38, 9)\",\n",
    "            \"FLOAT\": \"double\",\n",
    "            \"INTEGER\": \"long\",\n",
    "            \"DATETIME\": \"timestamp\",\n",
    "            \"STRING\": \"string\",\n",
    "            \"TIMESTAMP\": \"timestamp\",\n",
    "            \"DATE\": \"date\",\n",
    "            \"BOOLEAN\": \"boolean\",\n",
    "            \"NUMERIC\": \"decimal(38, 9)\",\n",
    "        }\n",
    "\n",
    "        def __bq_to_spark(schema: list, root: dict):\n",
    "            for column in schema:\n",
    "                if column[\"type\"] == \"RECORD\":\n",
    "                    if column[\"mode\"] == \"NULLABLE\":\n",
    "                        if \"list\" in [\n",
    "                            field[\"name\"] for field in column[\"record_fields\"]\n",
    "                        ]:\n",
    "\n",
    "                            spark_column = {\n",
    "                                \"metadata\": {},\n",
    "                                \"name\": column[\"name\"],\n",
    "                                \"nullable\": False,\n",
    "                                \"type\": {\n",
    "                                    \"containsNull\": True,\n",
    "                                    \"elementType\": {\"fields\": [], \"type\": \"struct\"},\n",
    "                                    \"type\": \"array\",\n",
    "                                },\n",
    "                            }\n",
    "\n",
    "                            root[\"fields\"].append(spark_column)\n",
    "\n",
    "                            __bq_to_spark(\n",
    "                                column[\"record_fields\"][0][\"record_fields\"][0][\n",
    "                                    \"record_fields\"\n",
    "                                ],\n",
    "                                spark_column[\"type\"][\"elementType\"],\n",
    "                            )\n",
    "                        else:\n",
    "                            spark_column = {\n",
    "                                \"metadata\": {},\n",
    "                                \"name\": column[\"name\"],\n",
    "                                \"nullable\": column[\"mode\"] == \"NULLABLE\",\n",
    "                                \"type\": \"struct\",\n",
    "                                \"fields\": [],\n",
    "                            }\n",
    "\n",
    "                            __bq_to_spark(column[\"fields\"], spark_column)\n",
    "                    else:\n",
    "                        spark_column = {\n",
    "                            \"metadata\": {},\n",
    "                            \"name\": column[\"name\"],\n",
    "                            \"nullable\": column[\"mode\"] == \"NULLABLE\",\n",
    "                            \"type\": \"array\",\n",
    "                        }\n",
    "\n",
    "                        root[\"fields\"].append(spark_column)\n",
    "                else:\n",
    "                    spark_column = {\n",
    "                        \"metadata\": {},\n",
    "                        \"name\": column[\"name\"],\n",
    "                        \"nullable\": column[\"mode\"] == \"NULLABLE\",\n",
    "                        \"type\": parse[column[\"type\"]],\n",
    "                    }\n",
    "\n",
    "                    root[\"fields\"].append(spark_column)\n",
    "\n",
    "            return root\n",
    "\n",
    "        spark_schema = __bq_to_spark(schema=bq_schema, root=root_spark_schema)\n",
    "\n",
    "        spark_schema2 = StructType.fromJson(spark_schema)\n",
    "\n",
    "        return spark_schema2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_parsed = _cast_json(df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringType()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_parsed[\"uf\"].dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.schema:\n",
    "    df = df.withColumn(\n",
    "        column.name,\n",
    "        col(column.name).cast(schema_parsed[column.name].dataType)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======================================>                 (22 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 22:23:43 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 53, schema size: 65\n",
      "CSV file: file:///Users/flavio.pangracio/www/tcc/estban_csv/202210_ESTBAN_AG.CSV\n",
      "23/04/02 22:23:45 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 53, schema size: 65\n",
      "CSV file: file:///Users/flavio.pangracio/www/tcc/estban_csv/202209_ESTBAN_AG.CSV\n",
      "23/04/02 22:23:45 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 53, schema size: 65\n",
      "CSV file: file:///Users/flavio.pangracio/www/tcc/estban_csv/202211_ESTBAN_AG.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:========================================>               (23 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 22:23:46 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 53, schema size: 65\n",
      "CSV file: file:///Users/flavio.pangracio/www/tcc/estban_csv/202207_ESTBAN_AG.CSV\n",
      "23/04/02 22:23:46 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 53, schema size: 65\n",
      "CSV file: file:///Users/flavio.pangracio/www/tcc/estban_csv/202208_ESTBAN_AG.CSV\n",
      "23/04/02 22:23:47 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 53, schema size: 65\n",
      "CSV file: file:///Users/flavio.pangracio/www/tcc/estban_csv/202212_ESTBAN_AG.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet(\"estban_cleared\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1b135cf00aea25e2c1ce863d8af8d56c0d89d3700e29a0f68fb663e26bf9f47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
